{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import PowerTransformer, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "import optuna\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMOTETransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state = random_state\n",
    "        self.smote = SMOTE(random_state=self.random_state)\n",
    "\n",
    "    def fit_resample(self, X, y):\n",
    "        return self.smote.fit_resample(X, y)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = pd.read_csv('input/train.csv')\n",
    "test_data = pd.read_csv('input/test.csv')\n",
    "\n",
    "# Impute missing ages with median\n",
    "train_data['Age'] = train_data['Age'].fillna(train_data['Age'].median())\n",
    "test_data['Age'] = test_data['Age'].fillna(test_data['Age'].median())\n",
    "\n",
    "# Impute missing embarkments\n",
    "most_frequent_embarked = train_data['Embarked'].mode()[0]\n",
    "train_data['Embarked'] = train_data['Embarked'].fillna(most_frequent_embarked)\n",
    "test_data['Embarked'] = test_data['Embarked'].fillna(most_frequent_embarked)\n",
    "\n",
    "# Combine train and test for preprocessing\n",
    "all_data = pd.concat([train_data, test_data], sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# Extract titles from names\n",
    "all_data['Title'] = all_data['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "all_data['Title'] = all_data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "all_data['Title'] = all_data['Title'].replace('Mlle', 'Miss')\n",
    "all_data['Title'] = all_data['Title'].replace('Ms', 'Miss')\n",
    "all_data['Title'] = all_data['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "# Create family size feature\n",
    "all_data['FamilySize'] = all_data['SibSp'] + all_data['Parch'] + 1\n",
    "\n",
    "# Create is_alone feature\n",
    "all_data['IsAlone'] = 0\n",
    "all_data.loc[all_data['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "# Extract deck from cabin\n",
    "all_data['Deck'] = all_data['Cabin'].str.slice(0,1)\n",
    "all_data['Deck'] = all_data['Deck'].fillna('U')\n",
    "\n",
    "# Bin age\n",
    "all_data['AgeBin'] = pd.cut(all_data['Age'], bins=[0, 12, 20, 40, 60, 100], labels=['Child', 'Teen', 'Adult', 'Senior', 'Elderly'])\n",
    "\n",
    "# Bin fare\n",
    "all_data['FareBin'] = pd.qcut(all_data['Fare'], q=4, labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "# Create interaction features\n",
    "all_data['Age*Class'] = all_data['Age'] * all_data['Pclass']\n",
    "all_data['Fare*Class'] = all_data['Fare'] * all_data['Pclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Deck</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>IsAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>U</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>C</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Very High</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>U</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>C</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Very High</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>U</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Fare  FamilySize  Pclass     Sex Embarked Title Deck AgeBin  \\\n",
       "0  22.0   7.2500           2       3    male        S    Mr    U  Adult   \n",
       "1  38.0  71.2833           2       1  female        C   Mrs    C  Adult   \n",
       "2  26.0   7.9250           1       3  female        S  Miss    U  Adult   \n",
       "3  35.0  53.1000           2       1  female        S   Mrs    C  Adult   \n",
       "4  35.0   8.0500           1       3    male        S    Mr    U  Adult   \n",
       "\n",
       "     FareBin  IsAlone  \n",
       "0        Low        0  \n",
       "1  Very High        0  \n",
       "2     Medium        1  \n",
       "3  Very High        0  \n",
       "4     Medium        1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Selection\n",
    "numeric_features = ['Age', 'Fare', 'FamilySize']\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked', 'Title', 'Deck', 'AgeBin', 'FareBin', 'IsAlone']\n",
    "\n",
    "# Split back into train and test\n",
    "train_data = all_data[all_data['Survived'].notna()].copy()\n",
    "test_data = all_data[all_data['Survived'].isna()].copy()\n",
    "\n",
    "X = train_data[numeric_features + categorical_features]\n",
    "y = train_data['Survived']\n",
    "\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "categorical_encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "X_encoded = pd.DataFrame(categorical_encoder.fit_transform(X[categorical_features]))\n",
    "X_encoded.columns = categorical_encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Combine with numeric features\n",
    "X_numeric = X[numeric_features].reset_index(drop=True)\n",
    "X_preprocessed = pd.concat([X_numeric, X_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 features based on mutual information:\n",
      "Sex_male             0.162521\n",
      "Title_Mr             0.152560\n",
      "Title_Mrs            0.083310\n",
      "Title_Miss           0.062254\n",
      "Pclass_3             0.035179\n",
      "FareBin_Very High    0.022639\n",
      "AgeBin_Child         0.019521\n",
      "Deck_C               0.018392\n",
      "Deck_U               0.016980\n",
      "Embarked_S           0.016954\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Mutual Information for feature selection\n",
    "mi_scores = mutual_info_classif(X_encoded, y)\n",
    "mi_scores = pd.Series(mi_scores, index=X_encoded.columns)\n",
    "mi_scores = mi_scores.sort_values(ascending=False)\n",
    "top_features = mi_scores.nlargest(10).index.tolist()\n",
    "\n",
    "print(\"\\nTop 10 features based on mutual information:\")\n",
    "print(mi_scores.nlargest(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Preprocessing\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', PowerTransformer())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(random_state=42)),\n",
    "    ('xgb', XGBClassifier(random_state=42)),\n",
    "    ('lgbm', LGBMClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create the stacking ensemble\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Optimization with Optuna\n",
    "def objective(trial):\n",
    "    rf_n_estimators = trial.suggest_int('rf_n_estimators', 100, 1000)\n",
    "    rf_max_depth = trial.suggest_int('rf_max_depth', 2, 32)\n",
    "    xgb_n_estimators = trial.suggest_int('xgb_n_estimators', 100, 1000)\n",
    "    xgb_max_depth = trial.suggest_int('xgb_max_depth', 2, 32)\n",
    "    lgbm_n_estimators = trial.suggest_int('lgbm_n_estimators', 100, 1000)\n",
    "    lgbm_max_depth = trial.suggest_int('lgbm_max_depth', 2, 32)\n",
    "\n",
    "    lgbm_params = {\n",
    "    'n_estimators': lgbm_n_estimators,\n",
    "    'max_depth': lgbm_max_depth,\n",
    "    'min_child_samples': trial.suggest_int('lgbm_min_child_samples', 1, 50),\n",
    "    'min_gain_to_split': trial.suggest_float('lgbm_min_gain_to_split', 0, 1),\n",
    "    'random_state': 42\n",
    "    }\n",
    "    \n",
    "    base_models = [\n",
    "        ('rf', RandomForestClassifier(n_estimators=rf_n_estimators, max_depth=rf_max_depth, random_state=42)),\n",
    "        ('xgb', XGBClassifier(n_estimators=xgb_n_estimators, max_depth=xgb_max_depth, random_state=42)),\n",
    "        ('lgbm', LGBMClassifier(**lgbm_params))\n",
    "    ]\n",
    "    \n",
    "    stacking_model = StackingClassifier(\n",
    "        estimators=base_models,\n",
    "        final_estimator=LogisticRegression(),\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('feature_selection', SelectKBest(score_func=mutual_info_classif, k=10)),\n",
    "        ('classifier', stacking_model)\n",
    "    ])\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    \n",
    "    def custom_cross_val_score(estimator, X, y, cv):\n",
    "        skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "        scores = []\n",
    "        \n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            \n",
    "            X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "            \n",
    "            estimator.fit(X_train_resampled, y_train_resampled)\n",
    "            scores.append(estimator.score(X_test, y_test))\n",
    "        \n",
    "        return np.array(scores)\n",
    "    \n",
    "    score = np.mean(custom_cross_val_score(pipeline, X_preprocessed, y, cv=5))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = study.best_params\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", study.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
